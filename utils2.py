import os
import random
from functools import partial

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

import timm
import torch
import torch.nn as nn
from torch.optim import AdamW
from torch.utils.data import DataLoader

import torchmetrics

from transformers import AutoModel, AutoTokenizer

from dataset import MultimodalDataset, collate_fn, get_transforms
from config import Config as config


class TrainingVisualizer:
    def __init__(self):
        self.train_losses = []
        self.train_mae_scores = []
        self.val_mae_scores = []
        self.train_rmse_scores = []
        self.val_rmse_scores = []
        self.epochs = []
        
    def update(self, epoch, train_loss, train_mae, val_mae, train_rmse=None, val_rmse=None):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–π —ç–ø–æ—Ö–∏"""
        self.epochs.append(epoch)
        self.train_losses.append(train_loss)
        self.train_mae_scores.append(train_mae)
        self.val_mae_scores.append(val_mae)
        if train_rmse is not None:
            self.train_rmse_scores.append(train_rmse)
        if val_rmse is not None:
            self.val_rmse_scores.append(val_rmse)
    
    def plot_metrics(self, save_path=None):
        """–°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫–∏ loss –∏ –º–µ—Ç—Ä–∏–∫ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # –ì—Ä–∞—Ñ–∏–∫ Loss
        ax1.plot(self.epochs, self.train_losses, 'b-', label='Train Loss', linewidth=2)
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.set_title('Training Loss (MSE)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ MAE
        ax2.plot(self.epochs, self.train_mae_scores, 'g-', label='Train MAE', linewidth=2)
        ax2.plot(self.epochs, self.val_mae_scores, 'r-', label='Val MAE', linewidth=2)
        if self.train_rmse_scores:
            ax2.plot(self.epochs, self.train_rmse_scores, 'g--', label='Train RMSE', alpha=0.7)
            ax2.plot(self.epochs, self.val_rmse_scores, 'r--', label='Val RMSE', alpha=0.7)
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Error (calories)')
        ax2.set_title('Regression Metrics Progress')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"–ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {save_path}")
        
        plt.show()
    
    def print_current_metrics(self, epoch, train_loss, train_mae, val_mae, train_rmse=None, val_rmse=None):
        """–ü–µ—á–∞—Ç–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ —Ç–µ–∫—É—â–µ–π —ç–ø–æ—Ö–∏ —Å —Ü–≤–µ—Ç–æ–≤—ã–º –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ–º"""
        loss_color = '\033[94m'  # —Å–∏–Ω–∏–π
        train_color = '\033[92m'  # –∑–µ–ª–µ–Ω—ã–π
        val_color = '\033[93m'    # –∂–µ–ª—Ç—ã–π
        reset_color = '\033[0m'   # —Å–±—Ä–æ—Å
        
        metrics_str = (f"Epoch {epoch:2d}/{config.EPOCHS} | "
                       f"{loss_color}Loss: {train_loss:.2f}{reset_color} | "
                       f"{train_color}Train MAE: {train_mae:.1f} kcal{reset_color} | "
                       f"{val_color}Val MAE: {val_mae:.1f} kcal{reset_color}")
        
        if train_rmse is not None and val_rmse is not None:
            metrics_str += f" | {train_color}Train RMSE: {train_rmse:.1f}{reset_color} | {val_color}Val RMSE: {val_rmse:.1f}{reset_color}"
        
        print(metrics_str)
    
    def save_metrics_to_file(self, filename="training_metrics.csv"):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ CSV —Ñ–∞–π–ª"""
        metrics_df = pd.DataFrame({
            'epoch': self.epochs,
            'train_loss': self.train_losses,
            'train_mae': self.train_mae_scores,
            'val_mae': self.val_mae_scores,
            'train_rmse': self.train_rmse_scores if self.train_rmse_scores else [None] * len(self.epochs),
            'val_rmse': self.val_rmse_scores if self.val_rmse_scores else [None] * len(self.epochs)
        })
        
        metrics_df.to_csv(filename, index=False)
        print(f"–ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {filename}")


def seed_everything(seed: int):
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.benchmark = True


def set_requires_grad(module: nn.Module, unfreeze_pattern="", verbose=False):
    if len(unfreeze_pattern) == 0:
        for _, param in module.named_parameters():
            param.requires_grad = False
        return

    pattern = unfreeze_pattern.split("|")

    for name, param in module.named_parameters():
        if any([name.startswith(p) for p in pattern]):
            param.requires_grad = True
            if verbose:
                print(f"–†–∞–∑–º–æ—Ä–æ–∂–µ–Ω —Å–ª–æ–π: {name}")
        else:
            param.requires_grad = False


class MultimodalCalorieModel(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.config = config
        
        # –¢–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å
        self.text_model = AutoModel.from_pretrained(config.TEXT_MODEL_NAME)
        
        # –í–∏–∑—É–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
        self.image_model = timm.create_model(
            config.IMAGE_MODEL_NAME,
            pretrained=True,
            num_classes=0
        )

        # –ü—Ä–æ–µ–∫—Ü–∏–æ–Ω–Ω—ã–µ —Å–ª–æ–∏
        self.text_proj = nn.Linear(self.text_model.config.hidden_size, config.HIDDEN_DIM)
        self.image_proj = nn.Linear(self.image_model.num_features, config.HIDDEN_DIM)
        
        # –°–ª–æ–π –¥–ª—è –º–∞—Å—Å—ã –±–ª—é–¥–∞
        self.mass_proj = nn.Linear(1, config.HIDDEN_DIM // 4)

        # Fusion –∏ —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä
        fusion_dim = config.HIDDEN_DIM * 2 + config.HIDDEN_DIM // 4  # text + image + mass
        
        self.regressor = nn.Sequential(
            nn.Linear(fusion_dim, config.HIDDEN_DIM),
            nn.LayerNorm(config.HIDDEN_DIM),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(config.HIDDEN_DIM, config.HIDDEN_DIM // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(config.HIDDEN_DIM // 2, 1)  # –û–¥–∏–Ω –≤—ã—Ö–æ–¥ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
        )

    def forward(self, input_ids, attention_mask, image, total_mass):
        # –¢–µ–∫—Å—Ç–æ–≤—ã–µ features
        text_features = self.text_model(input_ids, attention_mask).last_hidden_state[:, 0, :]
        text_emb = self.text_proj(text_features)
        
        # –í–∏–∑—É–∞–ª—å–Ω—ã–µ features
        image_features = self.image_model(image)
        image_emb = self.image_proj(image_features)
        
        # Features –º–∞—Å—Å—ã
        mass_emb = self.mass_proj(total_mass.unsqueeze(-1).float())
        
        # –ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è –≤—Å–µ—Ö features
        fused_emb = torch.cat([text_emb, image_emb, mass_emb], dim=1)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–∞–ª–æ—Ä–∏–π
        calories = self.regressor(fused_emb)
        return calories.squeeze(-1)  # (batch_size,)


def validate(model, val_loader, device, mae_metric, rmse_metric=None, r2_metric=None):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫"""
    model.eval()
    total_loss = 0.0
    all_predictions = []
    all_labels = []

    with torch.no_grad():
        for batch in val_loader:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            inputs = {
                'input_ids': batch['input_ids'].to(device),
                'attention_mask': batch['attention_mask'].to(device),
                'image': batch['images'].to(device),
                'total_mass': batch['total_mass'].to(device)
            }
            labels = batch['labels'].to(device)

            # Forward pass
            predictions = model(**inputs)
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            mae_metric.update(predictions, labels)
            if rmse_metric:
                rmse_metric.update(predictions, labels)
            if r2_metric:
                r2_metric.update(predictions, labels)
            
            # Loss –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            loss = nn.MSELoss()(predictions, labels)
            total_loss += loss.item()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            all_predictions.extend(predictions.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è R¬≤
    if len(all_predictions) < 2:
        print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è R¬≤ score (n={len(all_predictions)})")
    
    avg_loss = total_loss / len(val_loader)
    mae_score = mae_metric.compute().cpu().numpy()
    rmse_score = rmse_metric.compute().cpu().numpy() if rmse_metric else None
    r2_score = r2_metric.compute().cpu().numpy() if r2_metric and len(all_predictions) >= 2 else float('nan')
    
    return avg_loss, mae_score, rmse_score, r2_score


def train(config, device):
    seed_everything(config.SEED)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    visualizer = TrainingVisualizer()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    model = MultimodalCalorieModel(config).to(device)
    tokenizer = AutoTokenizer.from_pretrained(config.TEXT_MODEL_NAME)

    # –†–∞–∑–º–æ—Ä–æ–∑–∫–∞ —Å–ª–æ–µ–≤ (–±–∞–∑–æ–≤–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è)
    set_requires_grad(model.text_model,
                      unfreeze_pattern=config.TEXT_MODEL_UNFREEZE, verbose=True)
    set_requires_grad(model.image_model,
                      unfreeze_pattern=config.IMAGE_MODEL_UNFREEZE, verbose=True)

    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
    optimizer = AdamW([
        {'params': model.text_model.parameters(), 'lr': config.TEXT_LR},
        {'params': model.image_model.parameters(), 'lr': config.IMAGE_LR},
        {'params': list(model.text_proj.parameters()) + 
                   list(model.image_proj.parameters()) + 
                   list(model.mass_proj.parameters()) + 
                   list(model.regressor.parameters()), 
         'lr': config.CLASSIFIER_LR}
    ], weight_decay=0.01)

    criterion = nn.MSELoss()

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    transforms = get_transforms(config)
    val_transforms = get_transforms(config, ds_type="val")
    train_dataset = MultimodalDataset(config, transforms)
    val_dataset = MultimodalDataset(config, val_transforms, ds_type="val")
    train_loader = DataLoader(train_dataset,
                              batch_size=config.BATCH_SIZE,
                              shuffle=True,
                              collate_fn=partial(collate_fn, tokenizer=tokenizer))
    val_loader = DataLoader(val_dataset,
                            batch_size=config.BATCH_SIZE,
                            shuffle=False,
                            collate_fn=partial(collate_fn, tokenizer=tokenizer))

    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ - –ò–ù–ò–¶–ò–ê–õ–ò–ó–ò–†–£–ï–ú –ó–î–ï–°–¨
    mae_metric_train = torchmetrics.MeanAbsoluteError().to(device)
    mae_metric_val = torchmetrics.MeanAbsoluteError().to(device)
    rmse_metric_train = torchmetrics.MeanSquaredError(squared=False).to(device)
    rmse_metric_val = torchmetrics.MeanSquaredError(squared=False).to(device)
    r2_metric_train = torchmetrics.R2Score().to(device)
    r2_metric_val = torchmetrics.R2Score().to(device)

    best_mae_val = float('inf')
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)

    print("Training started!")
    print("=" * 80)
    print(f"Target: Calorie Regression | Train samples: {len(train_dataset)} | Val samples: {len(val_dataset)}")
    print("=" * 80)
    
    for epoch in range(config.EPOCHS):
        model.train()
        total_loss = 0.0

        # –°–ë–†–ê–°–´–í–ê–ï–ú –ú–ï–¢–†–ò–ö–ò –ü–ï–†–ï–î –≠–ü–û–•–û–ô
        mae_metric_train.reset()
        rmse_metric_train.reset()
        r2_metric_train.reset()

        for batch_idx, batch in enumerate(train_loader):
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            inputs = {
                'input_ids': batch['input_ids'].to(device),
                'attention_mask': batch['attention_mask'].to(device),
                'image': batch['images'].to(device),
                'total_mass': batch['total_mass'].to(device)
            }
            labels = batch['labels'].to(device)

            # Forward
            optimizer.zero_grad()
            predictions = model(**inputs)
            loss = criterion(predictions, labels)

            # Backward
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            total_loss += loss.item()

            # –û–ë–ù–û–í–õ–Ø–ï–ú –º–µ—Ç—Ä–∏–∫–∏, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –≤—ã–∑—ã–≤–∞–µ–º
            mae_metric_train.update(predictions, labels)
            rmse_metric_train.update(predictions, labels)
            r2_metric_train.update(predictions, labels)

        # –í–´–ß–ò–°–õ–Ø–ï–ú –º–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è –ü–û–°–õ–ï –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        avg_loss = total_loss / len(train_loader)
        train_mae = mae_metric_train.compute().cpu().numpy()
        train_rmse = rmse_metric_train.compute().cpu().numpy()
        train_r2 = r2_metric_train.compute().cpu().numpy()

        # –°–ë–†–ê–°–´–í–ê–ï–ú –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
        mae_metric_val.reset()
        rmse_metric_val.reset()
        r2_metric_val.reset()

        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        val_loss, val_mae, val_rmse, val_r2 = validate(
            model, val_loader, device, mae_metric_val, rmse_metric_val, r2_metric_val
        )

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ scheduler
        scheduler.step(val_mae)

        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        visualizer.update(epoch, avg_loss, train_mae, val_mae, train_rmse, val_rmse)
        
        # –ü–µ—á–∞—Ç—å –º–µ—Ç—Ä–∏–∫
        visualizer.print_current_metrics(epoch, avg_loss, train_mae, val_mae, train_rmse, val_rmse)
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤—ã–≤–æ–¥ R¬≤
        if not np.isnan(train_r2) and not np.isnan(val_r2):
            print(f"   R¬≤ Score - Train: {train_r2:.4f} | Val: {val_r2:.4f}")
        else:
            print(f"   R¬≤ Score - Train: N/A | Val: N/A (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö)")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        if val_mae < best_mae_val:
            best_mae_val = val_mae
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'epoch': epoch,
                'best_mae': best_mae_val
            }, config.SAVE_PATH)
            print(f"üöÄ New best model saved! Val MAE: {val_mae:.1f} kcal")

    print("=" * 80)
    print("Training completed!")
    print(f"Best validation MAE: {best_mae_val:.1f} kcal")
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    visualizer.plot_metrics(save_path="training_metrics.png")
    visualizer.save_metrics_to_file()
    
    return visualizer

def predict_single(model, tokenizer, transforms, dish_data, device):
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –±–ª—é–¥–∞"""
    model.eval()
    
    with torch.no_grad():
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        inputs = {
            'input_ids': tokenizer(
                dish_data['ingredients'], 
                return_tensors="pt", 
                padding=True, 
                truncation=True
            )['input_ids'].to(device),
            'attention_mask': tokenizer(
                dish_data['ingredients'], 
                return_tensors="pt", 
                padding=True, 
                truncation=True
            )['attention_mask'].to(device),
            'image': transforms(image=np.array(dish_data['image']))["image"].unsqueeze(0).to(device),
            'total_mass': torch.FloatTensor([dish_data['total_mass']]).to(device)
        }
        
        prediction = model(**inputs)
        return prediction.cpu().numpy()[0]


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    visualizer = train(config, device)