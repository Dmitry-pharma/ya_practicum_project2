import os
import random
from functools import partial

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

import timm
import torch
import torch.nn as nn
from torch.optim import AdamW
from torch.utils.data import DataLoader

import torchmetrics

from transformers import AutoModel, AutoTokenizer

from dataset import MultimodalDataset, collate_fn, get_transforms
# Ð˜ÐœÐŸÐžÐ Ð¢ Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•Ð: Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÐºÐ»Ð°ÑÑ Ñ attention Ð¸Ð· Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð´Ð°
from utils3_cross_attention import MultimodalCalorieModelWithAttention, CrossModalAttention
from config import Config as config

def plot_test_results(results_df, test_mae, test_rmse):
    """
    Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
    """
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    
    # Ð“Ñ€Ð°Ñ„Ð¸Ðº 1: ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ðµ vs Ð˜ÑÑ‚Ð¸Ð½Ð½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
    ax1.scatter(results_df['true_calories'], results_df['predicted_calories'], 
                alpha=0.6, s=50)
    ax1.plot([results_df['true_calories'].min(), results_df['true_calories'].max()],
             [results_df['true_calories'].min(), results_df['true_calories'].max()], 
             'r--', linewidth=2)
    ax1.set_xlabel('Ð˜ÑÑ‚Ð¸Ð½Ð½Ñ‹Ðµ ÐºÐ°Ð»Ð¾Ñ€Ð¸Ð¸ (kcal)')
    ax1.set_ylabel('ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ðµ ÐºÐ°Ð»Ð¾Ñ€Ð¸Ð¸ (kcal)')
    ax1.set_title(f'ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ vs Ð˜ÑÑ‚Ð¸Ð½Ð½Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ\nMAE: {test_mae:.1f} kcal, RMSE: {test_rmse:.1f} kcal')
    ax1.grid(True, alpha=0.3)
    
    # Ð“Ñ€Ð°Ñ„Ð¸Ðº 2: Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¾ÑˆÐ¸Ð±Ð¾Ðº
    ax2.hist(results_df['absolute_error'], bins=30, alpha=0.7, color='orange', edgecolor='black')
    ax2.axvline(results_df['absolute_error'].mean(), color='red', linestyle='--', 
                label=f'Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ: {results_df["absolute_error"].mean():.1f} kcal')
    ax2.set_xlabel('ÐÐ±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° (kcal)')
    ax2.set_ylabel('Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð°')
    ax2.set_title('Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ñ‹Ñ… Ð¾ÑˆÐ¸Ð±Ð¾Ðº')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Ð“Ñ€Ð°Ñ„Ð¸Ðº 3: ÐžÑˆÐ¸Ð±ÐºÐ° vs ÐœÐ°ÑÑÐ° Ð±Ð»ÑŽÐ´Ð°
    ax3.scatter(results_df['mass'], results_df['absolute_error'], alpha=0.6, s=50)
    ax3.set_xlabel('ÐœÐ°ÑÑÐ° Ð±Ð»ÑŽÐ´Ð° (g)')
    ax3.set_ylabel('ÐÐ±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° (kcal)')
    ax3.set_title('Ð—Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð¾Ñ‚ Ð¼Ð°ÑÑÑ‹ Ð±Ð»ÑŽÐ´Ð°')
    ax3.grid(True, alpha=0.3)
    
    # Ð“Ñ€Ð°Ñ„Ð¸Ðº 4: ÐžÑ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°
    ax4.hist(results_df['relative_error'].dropna(), bins=30, alpha=0.7, color='green', edgecolor='black')
    ax4.axvline(results_df['relative_error'].mean(), color='red', linestyle='--',
                label=f'Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ: {results_df["relative_error"].mean():.1f}%')
    ax4.set_xlabel('ÐžÑ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° (%)')
    ax4.set_ylabel('Ð§Ð°ÑÑ‚Ð¾Ñ‚Ð°')
    ax4.set_title('Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¾ÑˆÐ¸Ð±Ð¾Ðº')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('test_results_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

def test_model(config, device, model_path=None):
    """
    Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð° Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐµ Ñ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¾Ð¼
    """
    print("=" * 80)
    print("Ð¢Ð•Ð¡Ð¢Ð˜Ð ÐžÐ’ÐÐÐ˜Ð• ÐœÐžÐ”Ð•Ð›Ð˜ ÐÐ Ð¢Ð•Ð¡Ð¢ÐžÐ’ÐžÐ™ Ð’Ð«Ð‘ÐžÐ ÐšÐ•")
    print("=" * 80)
    
    # Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð•: Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ñ cross-modal attention
    model = MultimodalCalorieModelWithAttention(config).to(device)
    
    if model_path and os.path.exists(model_path):
        try:
            # ÐŸÐ¾Ð¿Ñ‹Ñ‚ÐºÐ° 1: Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ weights_only=True (Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ñ‹Ð¹ ÑÐ¿Ð¾ÑÐ¾Ð±)
            checkpoint = torch.load(model_path, map_location=device, weights_only=True)
            model.load_state_dict(checkpoint['model_state_dict'])
            print(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ñ‹Ð¼ ÑÐ¿Ð¾ÑÐ¾Ð±Ð¾Ð¼ Ð¸Ð·: {model_path}")
        except Exception as e:
            print(f"âš ï¸  Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð½Ðµ ÑƒÐ´Ð°Ð»Ð°ÑÑŒ: {e}")
            try:
                # ÐŸÐ¾Ð¿Ñ‹Ñ‚ÐºÐ° 2: Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ weights_only=False (Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ð´Ð¾Ð²ÐµÑ€ÑÐµÑ‚Ðµ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÑƒ)
                checkpoint = torch.load(model_path, map_location=device, weights_only=False)
                model.load_state_dict(checkpoint['model_state_dict'])
                print(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° Ñ weights_only=False Ð¸Ð·: {model_path}")
            except Exception as e2:
                print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {e2}")
                print("âš ï¸  Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð½ÐµÐ½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ")
    else:
        print("âŒ Ð¤Ð°Ð¹Ð» Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð½ÐµÐ½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ")
    
    tokenizer = AutoTokenizer.from_pretrained(config.TEXT_MODEL_NAME)
    
    # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
    test_transforms = get_transforms(config, ds_type="val")
    try:
        test_dataset = MultimodalDataset(config, test_transforms, ds_type="test")
        test_loader = DataLoader(
            test_dataset,
            batch_size=config.BATCH_SIZE,
            shuffle=False,
            collate_fn=partial(collate_fn, tokenizer=tokenizer)
        )
        print(f"âœ… Ð¢ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°: {len(test_dataset)} Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð¾Ð²")
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…: {e}")
        print("âš ï¸  ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ test split Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ…")
        return None
    
    # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸
    mae_metric = torchmetrics.MeanAbsoluteError().to(device)
    rmse_metric = torchmetrics.MeanSquaredError(squared=False).to(device)
    r2_metric = torchmetrics.R2Score().to(device)
    
    # Ð”Ð»Ñ ÑÐ±Ð¾Ñ€Ð° Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸
    all_predictions = []
    all_targets = []
    all_dish_ids = []
    all_ingredients = []
    all_masses = []
    all_errors = []
    all_attention_weights = []  # Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð•: ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ attention weights
    
    model.eval()
    with torch.no_grad():
        for batch_idx, batch in enumerate(test_loader):
            try:
                inputs = {
                    'input_ids': batch['input_ids'].to(device),
                    'attention_mask': batch['attention_mask'].to(device),
                    'image': batch['images'].to(device),
                    'total_mass': batch['total_mass'].to(device)
                }
                labels = batch['labels'].to(device)
                
                # Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð•: Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ñ‚ÐµÐ¿ÐµÑ€ÑŒ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÐºÐ¾Ñ€Ñ‚ÐµÐ¶ (predictions, attn_weights)
                predictions, attn_weights = model(**inputs)
                
                # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
                mae_metric.update(predictions, labels)
                rmse_metric.update(predictions, labels)
                r2_metric.update(predictions, labels)
                
                # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ
                batch_predictions = predictions.cpu().numpy()
                batch_targets = labels.cpu().numpy()
                batch_errors = np.abs(batch_predictions - batch_targets)
                
                all_predictions.extend(batch_predictions)
                all_targets.extend(batch_targets)
                all_errors.extend(batch_errors)
                all_attention_weights.extend(attn_weights.cpu().numpy())
                
                # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
                batch_indices = range(batch_idx * config.BATCH_SIZE, 
                                    batch_idx * config.BATCH_SIZE + len(batch_predictions))
                all_dish_ids.extend([test_dataset.df.iloc[i]['dish_id'] for i in batch_indices])
                all_ingredients.extend([test_dataset.df.iloc[i]['processed_ingredients'] for i in batch_indices])
                all_masses.extend(batch['total_mass'].cpu().numpy())
                
            except Exception as e:
                print(f"âš ï¸  ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð±Ð°Ñ‚Ñ‡Ð° {batch_idx}: {e}")
                continue
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ ÐµÑÑ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
    if len(all_predictions) == 0:
        print("âŒ ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°!")
        return None
    
    # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
    test_mae = mae_metric.compute().cpu().numpy()
    test_rmse = rmse_metric.compute().cpu().numpy()
    test_r2 = r2_metric.compute().cpu().numpy()
    
    print(f"\nðŸ“Š ÐžÐ‘Ð©ÐÐ¯ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ Ð¢Ð•Ð¡Ð¢Ð:")
    print(f"   MAE:  {test_mae:.1f} kcal")
    print(f"   RMSE: {test_rmse:.1f} kcal")
    print(f"   RÂ²:   {test_r2:.4f}")
    
    # Ð Ð°ÑÑ‡ÐµÑ‚ MAPE Ñ Ð·Ð°Ñ‰Ð¸Ñ‚Ð¾Ð¹ Ð¾Ñ‚ Ð´ÐµÐ»ÐµÐ½Ð¸Ñ Ð½Ð° Ð½Ð¾Ð»ÑŒ
    try:
        mape = np.mean(np.abs(np.array(all_errors) / np.array(all_targets)) * 100)
        print(f"   MAPE: {mape:.1f}%")
    except:
        print(f"   MAPE: Ð½ÐµÐ²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ Ð²Ñ‹Ñ‡Ð¸ÑÐ»Ð¸Ñ‚ÑŒ")
    
    # ÐÐ½Ð°Ð»Ð¸Ð· attention weights
    if len(all_attention_weights) > 0:
        attention_weights = np.array(all_attention_weights)
        avg_text_attention = attention_weights[:, 0, 0].mean()
        avg_image_attention = attention_weights[:, 0, 1].mean()
        print(f"   Attention Analysis:")
        print(f"     - Text: {avg_text_attention:.3f}")
        print(f"     - Image: {avg_image_attention:.3f}")
        print(f"     - Ratio (Text/Image): {avg_text_attention/avg_image_attention:.3f}")
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ DataFrame Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
    results_df = pd.DataFrame({
        'dish_id': all_dish_ids,
        'predicted_calories': all_predictions,
        'true_calories': all_targets,
        'absolute_error': all_errors,
        'mass': all_masses,
        'ingredients': all_ingredients
    })
    
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ Ð¾ÑˆÐ¸Ð±ÐºÑƒ Ñ Ð·Ð°Ñ‰Ð¸Ñ‚Ð¾Ð¹ Ð¾Ñ‚ Ð´ÐµÐ»ÐµÐ½Ð¸Ñ Ð½Ð° Ð½Ð¾Ð»ÑŒ
    results_df['relative_error'] = (results_df['absolute_error'] / results_df['true_calories']) * 100
    results_df['relative_error'] = results_df['relative_error'].replace([np.inf, -np.inf], np.nan)
    
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ attention weights Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
    if len(all_attention_weights) > 0:
        results_df['text_attention'] = [aw[0, 0] for aw in all_attention_weights]
        results_df['image_attention'] = [aw[0, 1] for aw in all_attention_weights]
    
    # ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚Ð¾Ð¿-10 Ñ…ÑƒÐ´ÑˆÐ¸Ñ… Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹
    print(f"\nðŸ”´ Ð¢ÐžÐŸ-10 Ð¥Ð£Ð”Ð¨Ð˜Ð¥ ÐŸÐ Ð•Ð”Ð¡ÐšÐÐ—ÐÐÐ˜Ð™ (Ð¿Ð¾ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð¾Ð¹ Ð¾ÑˆÐ¸Ð±ÐºÐµ):")
    worst_predictions = results_df.nlargest(10, 'absolute_error')
    for i, (idx, row) in enumerate(worst_predictions.iterrows(), 1):
        print(f"   {i:2d}. {row['dish_id']}:")
        print(f"       ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¾: {row['predicted_calories']:.0f} kcal | Ð˜ÑÑ‚Ð¸Ð½Ð°: {row['true_calories']:.0f} kcal")
        print(f"       ÐžÑˆÐ¸Ð±ÐºÐ°: {row['absolute_error']:.0f} kcal ({row['relative_error']:.1f}%)")
        print(f"       ÐœÐ°ÑÑÐ°: {row['mass']:.0f}g")
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾Ð± attention weights ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
        if 'text_attention' in row:
            print(f"       Attention - Text: {row['text_attention']:.3f}, Image: {row['image_attention']:.3f}")
        
        ingredients_preview = str(row['ingredients'])[:80] + "..." if len(str(row['ingredients'])) > 80 else str(row['ingredients'])
        print(f"       Ð˜Ð½Ð³Ñ€ÐµÐ´Ð¸ÐµÐ½Ñ‚Ñ‹: {ingredients_preview}")
        print()
    
    # ÐÐ½Ð°Ð»Ð¸Ð· Ñ‚Ð¾Ð¿-10 Ð»ÑƒÑ‡ÑˆÐ¸Ñ… Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ð¹
    print(f"\nðŸŸ¢ Ð¢ÐžÐŸ-10 Ð›Ð£Ð§Ð¨Ð˜Ð¥ ÐŸÐ Ð•Ð”Ð¡ÐšÐÐ—ÐÐÐ˜Ð™ (Ð¿Ð¾ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð¾Ð¹ Ð¾ÑˆÐ¸Ð±ÐºÐµ):")
    best_predictions = results_df.nsmallest(10, 'absolute_error')
    for i, (idx, row) in enumerate(best_predictions.iterrows(), 1):
        print(f"   {i:2d}. {row['dish_id']}:")
        print(f"       ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¾: {row['predicted_calories']:.0f} kcal | Ð˜ÑÑ‚Ð¸Ð½Ð°: {row['true_calories']:.0f} kcal")
        print(f"       ÐžÑˆÐ¸Ð±ÐºÐ°: {row['absolute_error']:.0f} kcal ({row['relative_error']:.1f}%)")
        print(f"       ÐœÐ°ÑÑÐ°: {row['mass']:.0f}g")
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾Ð± attention weights ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
        if 'text_attention' in row:
            print(f"       Attention - Text: {row['text_attention']:.3f}, Image: {row['image_attention']:.3f}")
        
        ingredients_preview = str(row['ingredients'])[:80] + "..." if len(str(row['ingredients'])) > 80 else str(row['ingredients'])
        print(f"       Ð˜Ð½Ð³Ñ€ÐµÐ´Ð¸ÐµÐ½Ñ‚Ñ‹: {ingredients_preview}")
        print()
    
    # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð¾ÑˆÐ¸Ð±ÐºÐ°Ð¼
    print(f"\nðŸ“ˆ Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ ÐŸÐž ÐžÐ¨Ð˜Ð‘ÐšÐÐœ:")
    print(f"   ÐœÐµÐ´Ð¸Ð°Ð½Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°: {np.median(all_errors):.1f} kcal")
    print(f"   Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð¾Ðµ Ð¾Ñ‚ÐºÐ»Ð¾Ð½ÐµÐ½Ð¸Ðµ Ð¾ÑˆÐ¸Ð±Ð¾Ðº: {np.std(all_errors):.1f} kcal")
    print(f"   ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°: {np.max(all_errors):.1f} kcal")
    print(f"   ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°: {np.min(all_errors):.1f} kcal")
    
    # ÐÐ½Ð°Ð»Ð¸Ð· Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð¾Ñ‚ attention weights
    if 'text_attention' in results_df.columns:
        print(f"\nðŸ” ÐÐÐÐ›Ð˜Ð— ATTENTION WEIGHTS:")
        high_text_attention = results_df[results_df['text_attention'] > 0.7]
        high_image_attention = results_df[results_df['image_attention'] > 0.7]
        
        if len(high_text_attention) > 0:
            print(f"   ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ñ Ð²Ñ‹ÑÐ¾ÐºÐ¸Ð¼ attention Ðº Ñ‚ÐµÐºÑÑ‚Ñƒ (>0.7):")
            print(f"     - Ð¡Ñ€ÐµÐ´Ð½ÑÑ Ð¾ÑˆÐ¸Ð±ÐºÐ°: {high_text_attention['absolute_error'].mean():.1f} kcal")
            print(f"     - ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾: {len(high_text_attention)}")
        
        if len(high_image_attention) > 0:
            print(f"   ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ñ Ð²Ñ‹ÑÐ¾ÐºÐ¸Ð¼ attention Ðº Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑŽ (>0.7):")
            print(f"     - Ð¡Ñ€ÐµÐ´Ð½ÑÑ Ð¾ÑˆÐ¸Ð±ÐºÐ°: {high_image_attention['absolute_error'].mean():.1f} kcal")
            print(f"     - ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾: {len(high_image_attention)}")
    
    # Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
    try:
        plot_test_results(results_df, test_mae, test_rmse)
    except Exception as e:
        print(f"âš ï¸  ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ð¸ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð²: {e}")
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
    try:
        results_df.to_csv('test_results_detailed.csv', index=False)
        print(f"\nðŸ’¾ Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð²: test_results_detailed.csv")
    except Exception as e:
        print(f"âš ï¸  ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²: {e}")
    
    return results_df

# ÐÐ»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (ÐµÑÐ»Ð¸ Ð¾ÑÐ½Ð¾Ð²Ð½Ð°Ñ Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚)
def load_model_safe(model_path, model, device):
    """Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ Ñ€Ð°Ð·Ð½Ñ‹Ð¼Ð¸ Ð¼ÐµÑ‚Ð¾Ð´Ð°Ð¼Ð¸"""
    methods = [
        # ÐœÐµÑ‚Ð¾Ð´ 1: Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ°
        lambda: torch.load(model_path, map_location=device, weights_only=True),
        # ÐœÐµÑ‚Ð¾Ð´ 2: Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð½Ñ‹Ð¼ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€Ð¾Ð¼
        lambda: torch.load(model_path, map_location=device, weights_only=False),
        # ÐœÐµÑ‚Ð¾Ð´ 3: Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð²ÐµÑÐ¾Ð²
        lambda: torch.load(model_path, map_location=device)
    ]
    
    for i, method in enumerate(methods):
        try:
            print(f"ÐŸÐ¾Ð¿Ñ‹Ñ‚ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð¼ {i+1}...")
            checkpoint = method()
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)
            print(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð¼ {i+1}")
            return True
        except Exception as e:
            print(f"âŒ ÐœÐµÑ‚Ð¾Ð´ {i+1} Ð½Ðµ ÑƒÐ´Ð°Ð»ÑÑ: {e}")
            continue
    
    print("âŒ Ð’ÑÐµ Ð¼ÐµÑ‚Ð¾Ð´Ñ‹ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¸ÑÑŒ")
    return False

# ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ð°Ñ Ð³Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ
if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸
    model_path = config.SAVE_PATH
    if not os.path.exists(model_path):
        print(f"âŒ Ð¤Ð°Ð¹Ð» Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½: {model_path}")
        print("âš ï¸  Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸")
        # ÐœÐ¾Ð¶Ð½Ð¾ Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð·Ð´ÐµÑÑŒ, ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾
        # from your_main_file import train
        # visualizer, trained_model = train(config, device)
    else:
        print(f"âœ… Ð¤Ð°Ð¹Ð» Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð½Ð°Ð¹Ð´ÐµÐ½: {model_path}")
    
    # Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
    print("\n" + "="*80)
    print("Ð—ÐÐŸÐ£Ð¡Ðš Ð¢Ð•Ð¡Ð¢Ð˜Ð ÐžÐ’ÐÐÐ˜Ð¯")
    print("="*80)
    
    test_results = test_model(config, device, model_path=model_path)
    
    if test_results is not None:
        # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· ÑÐ»Ð¾Ð¶Ð½Ñ‹Ñ… ÑÐ»ÑƒÑ‡Ð°ÐµÐ²
        print("\n" + "="*80)
        print("ÐÐÐÐ›Ð˜Ð— Ð¡Ð›ÐžÐ–ÐÐ«Ð¥ Ð¡Ð›Ð£Ð§ÐÐ•Ð’")
        print("="*80)
        
        # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð±Ð»ÑŽÐ´Ð° Ñ Ð½Ð°Ð¸Ð±Ð¾Ð»ÑŒÑˆÐµÐ¹ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾ÑˆÐ¸Ð±ÐºÐ¾Ð¹
        high_relative_error = test_results.nlargest(5, 'relative_error')
        print("Ð‘Ð»ÑŽÐ´Ð° Ñ Ð½Ð°Ð¸Ð±Ð¾Ð»ÑŒÑˆÐµÐ¹ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾ÑˆÐ¸Ð±ÐºÐ¾Ð¹ (>50%):")
        for idx, row in high_relative_error.iterrows():
            if row['relative_error'] > 50:
                print(f"   {row['dish_id']}: {row['relative_error']:.1f}% Ð¾ÑˆÐ¸Ð±ÐºÐ°")
                print(f"      Ð˜Ð½Ð³Ñ€ÐµÐ´Ð¸ÐµÐ½Ñ‚Ñ‹: {row['ingredients']}")
                if 'text_attention' in row:
                    print(f"      Attention - Text: {row['text_attention']:.3f}, Image: {row['image_attention']:.3f}")
                print()